{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "mols = Chem.SDMolSupplier('../data_files/Final_Dataset.csv')\n",
    "len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FFiNet.data_pipeline.data_generating import DataGenerating\n",
    "\n",
    "data_generate = DataGenerating(folder='../data_pipeline/data_files/',\n",
    "                                raw_dataset_name='Final_Dataset.csv',\n",
    "                                feature_dict_name='features_dict_Final_Dataset.npy',\n",
    "                                dataset_name='Final_Dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generate.features_generating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_generate.features_dict_exist = True\n",
    "target = pd.read_csv('../data_pipeline/data_files/Final_Dataset.csv').Density\n",
    "\n",
    "data_generate.dataset_creating(target_name=target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FFiNet.train_evaluate.utils import TrainArgs\n",
    "from FFiNet.train_evaluate.train_graph import evaluate\n",
    "from FFiNet.models.FFiNet_model import FFiNetModel\n",
    "import torch.nn as nn\n",
    "\n",
    "train_args = TrainArgs(\n",
    "                lr=0.001, \n",
    "                model_save_path='..\\\\train_evaluate\\\\saved_models\\\\',\n",
    "                batch_size=64, \n",
    "                patience=100, \n",
    "                task='regression',\n",
    "                num_tasks=1,\n",
    "                normalize=False, \n",
    "                interval=10,\n",
    "                task_name=['Final_Dataset'], \n",
    "                metrics='MAE',\n",
    "                num_epochs = 10000,\n",
    "                tolerance=0,  \n",
    "                save=True,\n",
    "                writer=False,\n",
    "                logs=True,\n",
    "                #split=[train_idx, valid_idx, test_idx], \n",
    "            )\n",
    "\n",
    "params = {\n",
    "    'hidden_dim': 16,\n",
    "    'hidden_layers': 3,\n",
    "    'num_heads': 8,\n",
    "    'activation': nn.PReLU(), \n",
    "    'dropout': 0.3,\n",
    "    'prediction_layers': 3,\n",
    "    'prediction_dropout': 0.3,\n",
    "    'prediction_hidden_dim': 256,\n",
    "}\n",
    "\n",
    "evaluate(3,\n",
    "        data_path='../data_pipeline/data_files/Final_Dataset.pt', \n",
    "        model_class=FFiNetModel, \n",
    "        model_args=params, \n",
    "        train_args=train_args\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Huang & Massa Dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before using Huang & Massa Dataset to test, the same data appear in both dataset should be removed from training\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from FFiNet.train_evaluate.utils import evaluate_score\n",
    "from FFiNet.models.FFiNet_model import FFiNetModel\n",
    "\n",
    "model1 = FFiNetModel(\n",
    "    feature_per_layer=[65 if train_args.task_name[0] == 'pdbbind' else + 66] + [params['hidden_dim']] * params['hidden_layers'], \n",
    "    num_heads=params['num_heads'], \n",
    "    pred_hidden_dim=params['prediction_hidden_dim'], \n",
    "    pred_dropout=params['prediction_dropout'], \n",
    "    pred_layers=params['prediction_layers'], \n",
    "    activation=params['activation'], \n",
    "    dropout=params['dropout'],\n",
    "    num_tasks=train_args.num_tasks\n",
    ")\n",
    "for num in range(3):\n",
    "    parameter1_dict = torch.load(f'../train_evaluate/saved_models/FFiNetModel_({num}).pt')\n",
    "    model1.load_state_dict(parameter1_dict)\n",
    "    model1.eval()\n",
    "\n",
    "    dataset = torch.load('../data_pipeline/data_files/Huang_&_Massa_density.pt')\n",
    "    dataset_i = DataLoader(dataset, batch_size=128)\n",
    "\n",
    "    for i, batch in enumerate(dataset_i):\n",
    "        batch = batch.to(train_args.device)\n",
    "        model1.to(train_args.device)\n",
    "        y_hat = model1(batch)\n",
    "        y_true = batch.y.reshape((-1, train_args.num_tasks))\n",
    "\n",
    "    val_metric = evaluate_score(model1, dataset_i, train_args)\n",
    "    print(val_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('my-rdkit-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14b33fc564aaf0fc1f155a8b3444fd33698f40437cd7759b3eabea974b52dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
